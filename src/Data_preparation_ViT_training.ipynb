{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libraries installation + imports"
      ],
      "metadata": {
        "id": "FehN3E3qsHxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guaen6lGsSJM",
        "outputId": "3d588c41-92ab-4584-c0f8-47788009a5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ],
      "metadata": {
        "id": "GWd-clfbsJWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Kaggle dataset(uplod kaggle.json) too"
      ],
      "metadata": {
        "id": "nyGBtr-br1RG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wHq7LG-rrV_"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Donwload to the Google drive directory"
      ],
      "metadata": {
        "id": "OSG5_cwxr4rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c isic-2024-challenge -p /content/drive/MyDrive/ML_project/kaggle"
      ],
      "metadata": {
        "id": "vFctWxJtsAws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_dir = '/content/drive/MyDrive/ML_project/kaggle'\n",
        "!unzip  \"{project_dir}/isic-2024-challenge.zip\" -d /content/isic-2024-challenge;"
      ],
      "metadata": {
        "id": "p42QA3N8sDZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/isic-2024-challenge'"
      ],
      "metadata": {
        "id": "w4JLtXn4sFpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore test dataset"
      ],
      "metadata": {
        "id": "8z0Ir_g5wxyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(f'{root_dir}/test-image.hdf5', 'r') as f:\n",
        "    print(\"Keys in the file:\", list(f.keys()))\n",
        "\n",
        "    keys = list(f.keys())\n",
        "    for key in keys:\n",
        "        dataset = f[key]\n",
        "        print(f\"\\nInspecting '{key}':\")\n",
        "\n",
        "        if dataset.shape == ():\n",
        "            print(f\"'{key}' is a scalar with value: {dataset[()]}\")\n",
        "        else:\n",
        "            print(f\"'{key}' is an array with shape: {dataset.shape}\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "7Ebc5XACwuNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the train images"
      ],
      "metadata": {
        "id": "rNJcm0xSw77G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = f'{root_dir}/train-image/image'\n",
        "\n",
        "all_images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "\n",
        "random_images = random.sample(all_images, 10)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, img_name in enumerate(random_images):\n",
        "    img_path = os.path.join(image_dir, img_name)\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(img_name)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-lmm7AsEw0tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hair removal algorithm"
      ],
      "metadata": {
        "id": "X9PxZYIFxGaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hair(image):\n",
        "    \"\"\"\n",
        "    Remove hair artifacts from an image using the DullRazor approach.\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "    _, thresh = cv2.threshold(blackhat, 12, 255, cv2.THRESH_BINARY)\n",
        "    inpainted = cv2.inpaint(image, thresh, inpaintRadius=1, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "    return inpainted"
      ],
      "metadata": {
        "id": "MFDcI_aoxCHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check resutls of hair removal alforithm"
      ],
      "metadata": {
        "id": "ZGSLL0O8xRzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, output_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocess an image by removing hair, resizing, and normalizing.\n",
        "    Also visualizes the image before and after hair removal.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_np = np.array(image)\n",
        "    hair_removed_image = remove_hair(image_np)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image_np)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(hair_removed_image)\n",
        "    plt.title(\"After Hair Removal\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    hair_removed_image = Image.fromarray(hair_removed_image)\n",
        "\n",
        "    preprocess_transform = transforms.Compose([\n",
        "        transforms.Resize(output_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image_tensor = preprocess_transform(hair_removed_image)\n",
        "\n",
        "    return image_tensor\n",
        "\n",
        "image_path = f'{root_dir}/train-image/image/ISIC_2314445.jpg'\n",
        "preprocessed_image = preprocess_image(image_path)"
      ],
      "metadata": {
        "id": "SsvZEfHpxNSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataset"
      ],
      "metadata": {
        "id": "292-pVo4xcSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(f'{root_dir}/train-metadata.csv')\n",
        "selected_data = data[['isic_id', 'target']]"
      ],
      "metadata": {
        "id": "f7Zb2bgHxgkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data that we take all present malignant data and only 5K of benign data"
      ],
      "metadata": {
        "id": "NQEReFflxp_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_target_1 = selected_data[selected_data['target'] == 1]\n",
        "\n",
        "num_samples_target_0 = 5000\n",
        "data_target_0 = selected_data[selected_data['target'] == 0].sample(n=num_samples_target_0, random_state=42)\n",
        "balanced_data = pd.concat([data_target_1, data_target_0], axis=0).reset_index(drop=True)\n",
        "\n",
        "print(balanced_data['target'].value_counts())"
      ],
      "metadata": {
        "id": "yl8f7KOVxo5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add [ISIC-2020 dataset:](https://www.kaggle.com/datasets/nischaydnk/isic-2020-jpg-256x256-resized)"
      ],
      "metadata": {
        "id": "ZuFiTVbIx5QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "92hA0vK8x7sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move downloaded dataset to desired location"
      ],
      "metadata": {
        "id": "gl7gRXs8yCbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /root/.cache/kagglehub/datasets/fanconic/skin-cancer-malignant-vs-benign/versions/4 /content/isic-2024-challenge/isic-2020-dataset"
      ],
      "metadata": {
        "id": "VXwJvjvAyBMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add new data to our dataset(only malignant images)"
      ],
      "metadata": {
        "id": "ghsnTZcjyIGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = os.listdir('/content/isic-2024-challenge/isic-2020-dataset/4/train/malignant/')\n",
        "\n",
        "isic_2020_dataset = pd.DataFrame({\n",
        "    'isic_id': ['ISIC2020_' + file for file in file_list],\n",
        "    'target': 1\n",
        "})"
      ],
      "metadata": {
        "id": "2szFhZONyQ5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_dataset = pd.concat([balanced_data, isic_2020_dataset], ignore_index=True)"
      ],
      "metadata": {
        "id": "YPDVz6EqzW3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depicts data distribution"
      ],
      "metadata": {
        "id": "zHEOHyVUyYiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = merged_dataset.target.value_counts()\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(value_counts.index, value_counts.values, color=['#1f77b4', '#ff7f0e'], edgecolor='black')\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 5, int(yval), ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title(\"Distribution of Target Values\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Target\", fontsize=14)\n",
        "plt.ylabel(\"Frequency\", fontsize=14)\n",
        "plt.xticks([0, 1], labels=['Class 0', 'Class 1'], fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X81WZg4ZyR9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data in the equal proportions"
      ],
      "metadata": {
        "id": "vIdraTlszMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(\n",
        "    merged_dataset, test_size=0.2, stratify=merged_dataset['target'], random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "IRZL0T0DzLY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loader for our dataset"
      ],
      "metadata": {
        "id": "PfbYbtviyiwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CassavaDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the PyTorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path='isic-2024-challenge/train-image/image/', secondary_data_path=\"/content/isic-2024-challenge/isic-2020-dataset/4/train/malignant\", mode=\"train\", transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.secondary_data_path = secondary_data_path\n",
        "        self.transforms = transforms\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        if img_name.startswith(\"ISIC2020_\"):\n",
        "            stripped_name = img_name.replace(\"ISIC2020_\", \"\")\n",
        "            img_path = os.path.join(self.secondary_data_path, f\"{stripped_name}\")\n",
        "        else:\n",
        "            img_path = os.path.join(self.data_path, f\"{img_name}.jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "Fv-bMgniyfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Preprocessing"
      ],
      "metadata": {
        "id": "rDHJbU3CysLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HairRemovalTransform:\n",
        "    def __call__(self, img):\n",
        "        img_np = np.array(img)\n",
        "        img_np = remove_hair(img_np)\n",
        "        img = Image.fromarray(img_np)\n",
        "        return img\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "        HairRemovalTransform(),\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_valid = transforms.Compose(\n",
        "    [\n",
        "        HairRemovalTransform(),\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "iQRnbSd8ylUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ViT model training"
      ],
      "metadata": {
        "id": "F3PkgnH4yybv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False, model_path=None):\n",
        "        super(ViTBase16, self).__init__()\n",
        "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
        "\n",
        "        if pretrained and model_path:\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n",
        "        self.model.train()\n",
        "        epoch_loss = 0.0\n",
        "        epoch_accuracy = 0.0\n",
        "\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_accuracy += accuracy.item()\n",
        "\n",
        "            optimizer.step()\n",
        "            if device.type == \"xla\" and i % 20 == 0:\n",
        "                xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        avg_accuracy = epoch_accuracy / len(train_loader)\n",
        "        return avg_loss, avg_accuracy\n",
        "\n",
        "    def validate_one_epoch(self, valid_loader, criterion, device):\n",
        "        self.model.eval()\n",
        "        valid_loss = 0.0\n",
        "        valid_accuracy = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in valid_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                output = self(data)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "\n",
        "                valid_loss += loss.item()\n",
        "                valid_accuracy += accuracy.item()\n",
        "\n",
        "        avg_loss = valid_loss / len(valid_loader)\n",
        "        avg_accuracy = valid_accuracy / len(valid_loader)\n",
        "        return avg_loss, avg_accuracy\n"
      ],
      "metadata": {
        "id": "Y3BHHRAKyxaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CassavaDataset(train_data, data_path='isic-2024-challenge/train-image/image/', transforms=transforms_train)\n",
        "valid_dataset = CassavaDataset(val_data, data_path='isic-2024-challenge/train-image/image/', transforms=transforms_valid)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "_2QhSIOfy9L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "KuMl9GJizwRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTBase16(n_classes=2, pretrained=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_accuracies = []\n",
        "valid_accuracies  = []\n",
        "\n",
        "num_epochs = 10\n",
        "best_valid_acc = 0.0\n",
        "total_time = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 20)\n",
        "    train_loss, train_acc = model.train_one_epoch(train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    print(f\"Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
        "\n",
        "    valid_loss, valid_acc = model.validate_one_epoch(valid_loader, criterion, device)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accuracies.append(valid_acc)\n",
        "    print(f\"Validation: Loss = {valid_loss:.4f}, Accuracy = {valid_acc:.4f}\")\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        print(f\"Validation accuracy improved from {best_valid_acc:.4f} to {valid_acc:.4f}. Saving model...\")\n",
        "        best_valid_acc = valid_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    total_time += epoch_time\n",
        "    avg_epoch_time = total_time / (epoch + 1)\n",
        "    time_left = avg_epoch_time * (num_epochs - epoch - 1)\n",
        "\n",
        "    print(f\"Time for epoch {epoch+1}: {epoch_time:.2f} seconds\")\n",
        "    print(f\"Estimated time remaining: {time_left:.2f} seconds\")\n",
        "\n",
        "    print(f\"\\nEpoch Summary: {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Accuracy: {valid_acc:.4f}\")\n",
        "    print(f\"Best Validation Accuracy so far: {best_valid_acc:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "9lAk-3G2zqqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}