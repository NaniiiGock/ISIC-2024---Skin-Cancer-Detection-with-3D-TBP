{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before this code execution, there is a need to download into root dir `kaggle.json` file with your credentials"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install pillow\n",
    "!pip install scikit-learn\n",
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions download -c isic-2024-challenge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip /content/isic-2024-challenge.zip  -d /content/isic-2024-challenge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_dir = '/content/isic-2024-challenge'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the given data provided in hdf5 format\n",
    "\n",
    "with h5py.File(f'{root_dir}/test-image.hdf5', 'r') as f:\n",
    "    print(\"Keys in the file:\", list(f.keys()))\n",
    "    keys = list(f.keys())\n",
    "    for key in keys:\n",
    "        dataset = f[key]\n",
    "        print(f\"\\nInspecting '{key}':\")\n",
    "        if dataset.shape == ():\n",
    "            print(f\"'{key}' is a scalar with value: {dataset[()]}\")\n",
    "        else:\n",
    "            print(f\"'{key}' is an array with shape: {dataset.shape}\")\n",
    "            plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize test dataset\n",
    "\n",
    "with h5py.File(f'{root_dir}/test-image.hdf5', 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(\"Keys in the file:\", keys)\n",
    "\n",
    "    for key in keys:\n",
    "        binary_data = f[key][()]\n",
    "        image = Image.open(BytesIO(binary_data))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(key)\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize random ten images from the train dataset\n",
    "\n",
    "image_dir = f'{root_dir}/train-image/image'\n",
    "images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "random_images = random.sample(images, 10)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, img_name in enumerate(random_images):\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(img_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_hair(image):\n",
    "    \"\"\"\n",
    "    Removes hair artifacts from an image using the DullRazor approach\n",
    "    :param image: np.ndarray\n",
    "    :return: np.ndarray\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _, thresh = cv2.threshold(blackhat, 12, 255, cv2.THRESH_BINARY)\n",
    "    inpainted = cv2.inpaint(image, thresh, inpaintRadius=1, flags=cv2.INPAINT_TELEA)\n",
    "    return inpainted\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, output_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess an image by removing hair, resizing, and normalizing\n",
    "    :param image_path: str\n",
    "    :param output_size: tuple\n",
    "    :return: torch.Tensor\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    hair_removed_image = remove_hair(image_np)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hair_removed_image)\n",
    "    plt.title(\"After Hair Removal\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    hair_removed_image = Image.fromarray(hair_removed_image)\n",
    "    preprocess_transform = transforms.Compose([\n",
    "        transforms.Resize(output_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image_tensor = preprocess_transform(hair_removed_image)\n",
    "\n",
    "    return image_tensor\n",
    "\n",
    "image_path = f'{root_dir}/train-image/image/ISIC_5186979.jpg'\n",
    "preprocessed_image = preprocess_image(image_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(ratio):\n",
    "    \"\"\"\n",
    "    Splits train data into two datasets - train and validation\n",
    "    :param ratio: float\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    base_dir = f'{root_dir}/train-image'\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    val_dir = os.path.join(base_dir, 'val')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    all_images = [img for img in os.listdir(preprocessed_image) if os.path.isfile(os.path.join(image_dir,img))]\n",
    "    train_images, val_images = train_test_split(all_images, train_size=ratio, random_state=42)\n",
    "\n",
    "    for img_name in train_images:\n",
    "        src_path = os.path.join(image_dir, img_name)\n",
    "        dst_path = os.path.join(train_dir, img_name)\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    for img_name in val_images:\n",
    "        src_path = os.path.join(image_dir, img_name)\n",
    "        dst_path = os.path.join(val_dir, img_name)\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    print(\"Dataset split completed.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
