{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaniiiGock/ISIC-2024---Skin-Cancer-Detection-with-3D-TBP/blob/main/Xgboost%20and%20LGBM%20model%20fine%20tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvZzt0utfcoO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv2IrbBNfxKM",
        "outputId": "e35d3cbd-c56e-4a21-9635-79e044429456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Pq9lDigDeW"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Machine Learning Project/train-metadata.csv', low_memory=False)\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Machine Learning Project/test-metadata.csv', low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5uCllA5gOnP"
      },
      "outputs": [],
      "source": [
        "useless_cols = set(train_data.columns) - set(test_data.columns)\n",
        "useless_cols.remove('target')\n",
        "useless_cols = list(useless_cols)\n",
        "train_data = train_data.drop(columns=useless_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwxwN3g7kO0W"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop(columns='target')\n",
        "y_train = train_data['target']\n",
        "X_train.fillna({'age_approx': X_train['age_approx'].mean(),'anatom_site_general':'NA','sex':'NA'}, inplace=True)\n",
        "test_data.fillna({'age_approx': X_train['age_approx'].mean(),'anatom_site_general':'NA','sex':'NA'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "n-mD46Cj3dOj"
      },
      "outputs": [],
      "source": [
        "all_data = X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ69-Fmcik3D"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Step 1: Handle Missing Values in Test Data\n",
        "numerical_cols = test_data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
        "categorical_cols = test_data.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "imputation_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_imputer, numerical_cols),\n",
        "        ('cat', cat_imputer, categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'  # Keep other columns as they are\n",
        ")\n",
        "imputation_transformer.fit(X_train)\n",
        "\n",
        "# Apply the transformation\n",
        "test_data = pd.DataFrame(\n",
        "    imputation_transformer.transform(test_data),\n",
        "    columns=numerical_cols + categorical_cols\n",
        ")\n",
        "\n",
        "# Step 2: Restore Original Data Types\n",
        "# Ensure numerical columns are float\n",
        "for col in numerical_cols:\n",
        "    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
        "\n",
        "# Ensure categorical columns are category\n",
        "for col in categorical_cols:\n",
        "    test_data[col] = test_data[col].astype('object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGaLoXC_OPDy"
      },
      "outputs": [],
      "source": [
        "all_data[\"lesion_size_ratio\"] = all_data[\"tbp_lv_minorAxisMM\"] / all_data[\"clin_size_long_diam_mm\"]\n",
        "all_data[\"lesion_shape_index\"] = all_data[\"tbp_lv_areaMM2\"] / (all_data[\"tbp_lv_perimeterMM\"] ** 2)\n",
        "all_data[\"hue_contrast\"] = (all_data[\"tbp_lv_H\"] - all_data[\"tbp_lv_Hext\"]).abs()\n",
        "all_data[\"luminance_contrast\"] = (all_data[\"tbp_lv_L\"] - all_data[\"tbp_lv_Lext\"]).abs()\n",
        "all_data[\"lesion_color_difference\"] = np.sqrt(all_data[\"tbp_lv_deltaA\"] ** 2 + all_data[\"tbp_lv_deltaB\"] ** 2 + all_data[\"tbp_lv_deltaL\"] ** 2)\n",
        "all_data[\"border_complexity\"] = all_data[\"tbp_lv_norm_border\"] + all_data[\"tbp_lv_symm_2axis\"]\n",
        "all_data[\"3d_position_distance\"] = np.sqrt(all_data[\"tbp_lv_x\"] ** 2 + all_data[\"tbp_lv_y\"] ** 2 + all_data[\"tbp_lv_z\"] ** 2)\n",
        "all_data[\"perimeter_to_area_ratio\"] = all_data[\"tbp_lv_perimeterMM\"] / all_data[\"tbp_lv_areaMM2\"]\n",
        "all_data[\"area_to_perimeter_ratio\"] = all_data[\"tbp_lv_areaMM2\"] / all_data[\"tbp_lv_perimeterMM\"]\n",
        "all_data[\"lesion_visibility_score\"] = all_data[\"tbp_lv_deltaLBnorm\"] + all_data[\"tbp_lv_norm_color\"]\n",
        "all_data[\"combined_anatomical_site\"] = all_data[\"anatom_site_general\"] + \"_\" + all_data[\"tbp_lv_location\"]\n",
        "all_data[\"symmetry_border_consistency\"] = all_data[\"tbp_lv_symm_2axis\"] * all_data[\"tbp_lv_norm_border\"]\n",
        "all_data[\"consistency_symmetry_border\"] = all_data[\"tbp_lv_symm_2axis\"] * all_data[\"tbp_lv_norm_border\"] / (all_data[\"tbp_lv_symm_2axis\"] + all_data[\"tbp_lv_norm_border\"])\n",
        "all_data[\"color_consistency\"] = all_data[\"tbp_lv_stdL\"] / all_data[\"tbp_lv_Lext\"]\n",
        "all_data[\"consistency_color\"] = all_data[\"tbp_lv_stdL\"] * all_data[\"tbp_lv_Lext\"] / (all_data[\"tbp_lv_stdL\"] + all_data[\"tbp_lv_Lext\"])\n",
        "all_data[\"size_age_interaction\"] = all_data[\"clin_size_long_diam_mm\"] * all_data[\"age_approx\"]\n",
        "all_data[\"hue_color_std_interaction\"] = all_data[\"tbp_lv_H\"] * all_data[\"tbp_lv_color_std_mean\"]\n",
        "all_data[\"lesion_severity_index\"] = (all_data[\"tbp_lv_norm_border\"] + all_data[\"tbp_lv_norm_color\"] + all_data[\"tbp_lv_eccentricity\"]) / 3\n",
        "all_data[\"shape_complexity_index\"] = all_data[\"border_complexity\"] + all_data[\"lesion_shape_index\"]\n",
        "all_data[\"color_contrast_index\"] = all_data[\"tbp_lv_deltaA\"] + all_data[\"tbp_lv_deltaB\"] + all_data[\"tbp_lv_deltaL\"] + all_data[\"tbp_lv_deltaLBnorm\"]\n",
        "all_data[\"log_lesion_area\"] = np.log(all_data[\"tbp_lv_areaMM2\"] + 1)\n",
        "all_data[\"mean_hue_difference\"] = (all_data[\"tbp_lv_H\"] + all_data[\"tbp_lv_Hext\"]) / 2\n",
        "all_data[\"std_dev_contrast\"] = np.sqrt((all_data[\"tbp_lv_deltaA\"] ** 2 + all_data[\"tbp_lv_deltaB\"] ** 2 + all_data[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
        "all_data[\"color_shape_composite_index\"] = (all_data[\"tbp_lv_color_std_mean\"] + all_data[\"tbp_lv_area_perim_ratio\"] + all_data[\"tbp_lv_symm_2axis\"]) / 3\n",
        "all_data[\"3d_lesion_orientation\"] = np.arctan2(all_data[\"tbp_lv_y\"], all_data[\"tbp_lv_x\"])\n",
        "all_data[\"overall_color_difference\"] = (all_data[\"tbp_lv_deltaA\"] + all_data[\"tbp_lv_deltaB\"] + all_data[\"tbp_lv_deltaL\"]) / 3\n",
        "all_data[\"symmetry_perimeter_interaction\"] = all_data[\"tbp_lv_symm_2axis\"] * all_data[\"tbp_lv_perimeterMM\"]\n",
        "all_data[\"comprehensive_lesion_index\"] = (all_data[\"tbp_lv_area_perim_ratio\"] + all_data[\"tbp_lv_eccentricity\"] + all_data[\"tbp_lv_norm_color\"] + all_data[\"tbp_lv_symm_2axis\"]) / 4\n",
        "all_data[\"color_variance_ratio\"] = all_data[\"tbp_lv_color_std_mean\"] / all_data[\"tbp_lv_stdLExt\"]\n",
        "all_data[\"border_color_interaction\"] = all_data[\"tbp_lv_norm_border\"] * all_data[\"tbp_lv_norm_color\"]\n",
        "all_data[\"border_color_interaction_2\"] = all_data[\"tbp_lv_norm_border\"] * all_data[\"tbp_lv_norm_color\"] / (all_data[\"tbp_lv_norm_border\"] + all_data[\"tbp_lv_norm_color\"])\n",
        "all_data[\"size_color_contrast_ratio\"] = all_data[\"clin_size_long_diam_mm\"] / all_data[\"tbp_lv_deltaLBnorm\"]\n",
        "all_data[\"age_normalized_nevi_confidence_2\"] = np.sqrt(all_data[\"clin_size_long_diam_mm\"]**2 + all_data[\"age_approx\"]**2)\n",
        "all_data[\"color_asymmetry_index\"] = all_data[\"tbp_lv_radial_color_std_max\"] * all_data[\"tbp_lv_symm_2axis\"]\n",
        "all_data[\"volume_approximation_3d\"] = all_data[\"tbp_lv_areaMM2\"] * np.sqrt((all_data[\"tbp_lv_x\"]**2 + all_data[\"tbp_lv_y\"]**2 + all_data[\"tbp_lv_z\"]**2))\n",
        "all_data[\"color_range \"] = (all_data[\"tbp_lv_L\"] - all_data[\"tbp_lv_Lext\"]).abs() + (all_data[\"tbp_lv_A\"] - all_data[\"tbp_lv_Aext\"]).abs() + (all_data[\"tbp_lv_B\"] - all_data[\"tbp_lv_Bext\"]).abs()\n",
        "all_data[\"shape_color_consistency\"] = all_data[\"tbp_lv_eccentricity\"] * all_data[\"tbp_lv_color_std_mean\"]\n",
        "all_data[\"border_length_ratio\"] = all_data[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(all_data[\"tbp_lv_areaMM2\"] / np.pi))\n",
        "all_data[\"age_size_symmetry_index\"] = all_data[\"age_approx\"] * all_data[\"clin_size_long_diam_mm\"] * all_data[\"tbp_lv_symm_2axis\"]\n",
        "all_data[\"index_age_size_symmetry\"] = all_data[\"age_approx\"] * all_data[\"tbp_lv_areaMM2\"] * all_data[\"tbp_lv_symm_2axis\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbmBgY0z3c3e"
      },
      "outputs": [],
      "source": [
        "test_data[\"lesion_size_ratio\"] = test_data[\"tbp_lv_minorAxisMM\"] / test_data[\"clin_size_long_diam_mm\"]\n",
        "test_data[\"lesion_shape_index\"] = test_data[\"tbp_lv_areaMM2\"] / (test_data[\"tbp_lv_perimeterMM\"] ** 2)\n",
        "test_data[\"hue_contrast\"] = (test_data[\"tbp_lv_H\"] - test_data[\"tbp_lv_Hext\"]).abs()\n",
        "test_data[\"luminance_contrast\"] = (test_data[\"tbp_lv_L\"] - test_data[\"tbp_lv_Lext\"]).abs()\n",
        "test_data[\"lesion_color_difference\"] = np.sqrt(test_data[\"tbp_lv_deltaA\"] ** 2 + test_data[\"tbp_lv_deltaB\"] ** 2 + test_data[\"tbp_lv_deltaL\"] ** 2)\n",
        "test_data[\"border_complexity\"] = test_data[\"tbp_lv_norm_border\"] + test_data[\"tbp_lv_symm_2axis\"]\n",
        "test_data[\"3d_position_distance\"] = np.sqrt(test_data[\"tbp_lv_x\"] ** 2 + test_data[\"tbp_lv_y\"] ** 2 + test_data[\"tbp_lv_z\"] ** 2)\n",
        "test_data[\"perimeter_to_area_ratio\"] = test_data[\"tbp_lv_perimeterMM\"] / test_data[\"tbp_lv_areaMM2\"]\n",
        "test_data[\"area_to_perimeter_ratio\"] = test_data[\"tbp_lv_areaMM2\"] / test_data[\"tbp_lv_perimeterMM\"]\n",
        "test_data[\"lesion_visibility_score\"] = test_data[\"tbp_lv_deltaLBnorm\"] + test_data[\"tbp_lv_norm_color\"]\n",
        "test_data[\"combined_anatomical_site\"] = test_data[\"anatom_site_general\"] + \"_\" + test_data[\"tbp_lv_location\"]\n",
        "test_data[\"symmetry_border_consistency\"] = test_data[\"tbp_lv_symm_2axis\"] * test_data[\"tbp_lv_norm_border\"]\n",
        "test_data[\"consistency_symmetry_border\"] = test_data[\"tbp_lv_symm_2axis\"] * test_data[\"tbp_lv_norm_border\"] / (test_data[\"tbp_lv_symm_2axis\"] + test_data[\"tbp_lv_norm_border\"])\n",
        "test_data[\"color_consistency\"] = test_data[\"tbp_lv_stdL\"] / test_data[\"tbp_lv_Lext\"]\n",
        "test_data[\"consistency_color\"] = test_data[\"tbp_lv_stdL\"] * test_data[\"tbp_lv_Lext\"] / (test_data[\"tbp_lv_stdL\"] + test_data[\"tbp_lv_Lext\"])\n",
        "test_data[\"size_age_interaction\"] = test_data[\"clin_size_long_diam_mm\"] * test_data[\"age_approx\"]\n",
        "test_data[\"hue_color_std_interaction\"] = test_data[\"tbp_lv_H\"] * test_data[\"tbp_lv_color_std_mean\"]\n",
        "test_data[\"lesion_severity_index\"] = (test_data[\"tbp_lv_norm_border\"] + test_data[\"tbp_lv_norm_color\"] + test_data[\"tbp_lv_eccentricity\"]) / 3\n",
        "test_data[\"shape_complexity_index\"] = test_data[\"border_complexity\"] + test_data[\"lesion_shape_index\"]\n",
        "test_data[\"color_contrast_index\"] = test_data[\"tbp_lv_deltaA\"] + test_data[\"tbp_lv_deltaB\"] + test_data[\"tbp_lv_deltaL\"] + test_data[\"tbp_lv_deltaLBnorm\"]\n",
        "test_data[\"log_lesion_area\"] = np.log(test_data[\"tbp_lv_areaMM2\"] + 1)\n",
        "test_data[\"mean_hue_difference\"] = (test_data[\"tbp_lv_H\"] + test_data[\"tbp_lv_Hext\"]) / 2\n",
        "test_data[\"std_dev_contrast\"] = np.sqrt((test_data[\"tbp_lv_deltaA\"] ** 2 + test_data[\"tbp_lv_deltaB\"] ** 2 + test_data[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
        "test_data[\"color_shape_composite_index\"] = (test_data[\"tbp_lv_color_std_mean\"] + test_data[\"tbp_lv_area_perim_ratio\"] + test_data[\"tbp_lv_symm_2axis\"]) / 3\n",
        "test_data[\"3d_lesion_orientation\"] = np.arctan2(test_data[\"tbp_lv_y\"], test_data[\"tbp_lv_x\"])\n",
        "test_data[\"overall_color_difference\"] = (test_data[\"tbp_lv_deltaA\"] + test_data[\"tbp_lv_deltaB\"] + test_data[\"tbp_lv_deltaL\"]) / 3\n",
        "test_data[\"symmetry_perimeter_interaction\"] = test_data[\"tbp_lv_symm_2axis\"] * test_data[\"tbp_lv_perimeterMM\"]\n",
        "test_data[\"comprehensive_lesion_index\"] = (test_data[\"tbp_lv_area_perim_ratio\"] + test_data[\"tbp_lv_eccentricity\"] + test_data[\"tbp_lv_norm_color\"] + test_data[\"tbp_lv_symm_2axis\"]) / 4\n",
        "test_data[\"color_variance_ratio\"] = test_data[\"tbp_lv_color_std_mean\"] / test_data[\"tbp_lv_stdLExt\"]\n",
        "test_data[\"border_color_interaction\"] = test_data[\"tbp_lv_norm_border\"] * test_data[\"tbp_lv_norm_color\"]\n",
        "test_data[\"border_color_interaction_2\"] = test_data[\"tbp_lv_norm_border\"] * test_data[\"tbp_lv_norm_color\"] / (test_data[\"tbp_lv_norm_border\"] + test_data[\"tbp_lv_norm_color\"])\n",
        "test_data[\"size_color_contrast_ratio\"] = test_data[\"clin_size_long_diam_mm\"] / test_data[\"tbp_lv_deltaLBnorm\"]\n",
        "test_data[\"age_normalized_nevi_confidence_2\"] = np.sqrt(test_data[\"clin_size_long_diam_mm\"]**2 + test_data[\"age_approx\"]**2)\n",
        "test_data[\"color_asymmetry_index\"] = test_data[\"tbp_lv_radial_color_std_max\"] * test_data[\"tbp_lv_symm_2axis\"]\n",
        "test_data[\"volume_approximation_3d\"] = test_data[\"tbp_lv_areaMM2\"] * np.sqrt((test_data[\"tbp_lv_x\"]**2 + test_data[\"tbp_lv_y\"]**2 + test_data[\"tbp_lv_z\"]**2))\n",
        "test_data[\"color_range \"] = (test_data[\"tbp_lv_L\"] - test_data[\"tbp_lv_Lext\"]).abs() + (test_data[\"tbp_lv_A\"] - test_data[\"tbp_lv_Aext\"]).abs() + (test_data[\"tbp_lv_B\"] - test_data[\"tbp_lv_Bext\"]).abs()\n",
        "test_data[\"shape_color_consistency\"] = test_data[\"tbp_lv_eccentricity\"] * test_data[\"tbp_lv_color_std_mean\"]\n",
        "test_data[\"border_length_ratio\"] = test_data[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(test_data[\"tbp_lv_areaMM2\"] / np.pi))\n",
        "test_data[\"age_size_symmetry_index\"] = test_data[\"age_approx\"] * test_data[\"clin_size_long_diam_mm\"] * test_data[\"tbp_lv_symm_2axis\"]\n",
        "test_data[\"index_age_size_symmetry\"] = test_data[\"age_approx\"] * test_data[\"tbp_lv_areaMM2\"] * test_data[\"tbp_lv_symm_2axis\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx333ixtO3X9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IudSFi8P2_ew"
      },
      "outputs": [],
      "source": [
        "all_data = all_data.drop(columns=['copyright_license', 'attribution', 'image_type'])\n",
        "test_data = test_data.drop(columns=['copyright_license', 'attribution', 'image_type'])\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "col_num = []\n",
        "col_cat = []\n",
        "for col in all_data:\n",
        "  if col in ['isic_id', 'patient_id']: continue;\n",
        "  if all_data[col].dtype == 'object':\n",
        "    col_cat.append(col)\n",
        "    all_data[col] = all_data[col].astype('category')\n",
        "    test_data[col] = test_data[col].astype('category')\n",
        "  else:\n",
        "    col_num.append(col)\n",
        "    all_data[col] = all_data[col].astype('float')\n",
        "    test_data[col] = test_data[col].astype('float')\n",
        "\n",
        "X_train = all_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siOv8bWcrKJl"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_transformer, col_num),\n",
        "        ('cat', cat_transformer, col_cat)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzzsj8JcuAoE"
      },
      "outputs": [],
      "source": [
        "import pandas.api.types\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80) -> float:\n",
        "    '''\n",
        "    2024 ISIC Challenge metric: pAUC\n",
        "\n",
        "    Given a solution file and submission file, this function returns the\n",
        "    the partial area under the receiver operating characteristic (pAUC)\n",
        "    above a given true positive rate (TPR) = 0.80.\n",
        "    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n",
        "\n",
        "    (c) 2024 Nicholas R Kurtansky, MSKCC\n",
        "\n",
        "    Args:\n",
        "        solution: ground truth pd.DataFrame of 1s and 0s\n",
        "        submission: solution dataframe of predictions of scores ranging [0, 1]\n",
        "\n",
        "    Returns:\n",
        "        Float value range [0, max_fpr]\n",
        "    '''\n",
        "\n",
        "    #del solution[row_id_column_name]\n",
        "    #del submission[row_id_column_name]\n",
        "\n",
        "    # check submission is numeric\n",
        "    if not pandas.api.types.is_numeric_dtype(submission.values):\n",
        "        raise ParticipantVisibleError('Submission target column must be numeric')\n",
        "\n",
        "    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "\n",
        "    # flip the submissions to their compliments\n",
        "    v_pred = -1.0*np.asarray(submission.values)\n",
        "\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "\n",
        "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
        "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
        "    if max_fpr is None or max_fpr == 1:\n",
        "        return auc(fpr, tpr)\n",
        "    if max_fpr <= 0 or max_fpr > 1:\n",
        "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
        "\n",
        "    # Add a single point at max_fpr by linear interpolation\n",
        "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
        "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
        "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
        "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
        "    fpr = np.append(fpr[:stop], max_fpr)\n",
        "    partial_auc = auc(fpr, tpr)\n",
        "\n",
        "#     # Equivalent code that uses sklearn's roc_auc_score\n",
        "#     v_gt = abs(np.asarray(solution.values)-1)\n",
        "#     v_pred = np.array([1.0 - x for x in submission.values])\n",
        "#     max_fpr = abs(1-min_tpr)\n",
        "#     partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "#     # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
        "#     # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
        "#     partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "\n",
        "    return(partial_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuLS0DaSuOHi",
        "outputId": "879b3997-6b6d-4a9d-d4fc-44d27f3f201b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "def custom_auc_scorer(y_true, y_pred_proba):\n",
        "    solution = pd.DataFrame(y_true, columns=[\"target\"])\n",
        "    submission = pd.DataFrame(y_pred_proba, columns=[\"pred\"])\n",
        "    return score(solution, submission, row_id_column_name=\"target\", min_tpr=0.80)\n",
        "custom_scorer = make_scorer(custom_auc_scorer, needs_proba=True, greater_is_better=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NHYcvqB9fAA",
        "outputId": "864440b4-a47a-4e52-dcaf-ef69bb65d3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n",
            "Downloading bayesian_optimization-2.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-2.0.1 colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mcOg46Ko9UGL",
        "outputId": "02bead29-16bf-43b2-a8e2-a9caf370f201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py:344: UserWarning: You're attempting to register an np.ndarray. Currently, the optimizer internally sorts parameters by key and expects any registered array to respect this order. In future versions this behaviour will change and the order as given by the pbounds dictionary will be used. If you wish to retain sorted parameters, please manually sort your pbounds dictionary before constructing the optimizer.\n",
            "  warn(msg, stacklevel=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| \u001b[39m1        \u001b[39m | \u001b[39m0.1541   \u001b[39m | \u001b[39m0.8174   \u001b[39m | \u001b[39m0.08351  \u001b[39m | \u001b[39m0.06943  \u001b[39m | \u001b[39m13.29    \u001b[39m | \u001b[39m1.09     \u001b[39m | \u001b[39m209.4    \u001b[39m | \u001b[39m0.6707   \u001b[39m | \u001b[39m0.8433   \u001b[39m | \u001b[39m0.6547   \u001b[39m |\n",
            "| \u001b[39m2        \u001b[39m | \u001b[39m0.1468   \u001b[39m | \u001b[39m0.83     \u001b[39m | \u001b[39m0.2674   \u001b[39m | \u001b[39m0.03929  \u001b[39m | \u001b[39m6.039    \u001b[39m | \u001b[39m3.059    \u001b[39m | \u001b[39m297.7    \u001b[39m | \u001b[39m0.9786   \u001b[39m | \u001b[39m0.8305   \u001b[39m | \u001b[39m0.6688   \u001b[39m |\n",
            "| \u001b[35m3        \u001b[39m | \u001b[35m0.1542   \u001b[39m | \u001b[35m0.9265   \u001b[39m | \u001b[35m0.08222  \u001b[39m | \u001b[35m0.07044  \u001b[39m | \u001b[35m14.34    \u001b[39m | \u001b[35m16.54    \u001b[39m | \u001b[35m402.5    \u001b[39m | \u001b[35m0.1754   \u001b[39m | \u001b[35m0.4355   \u001b[39m | \u001b[35m0.6023   \u001b[39m |\n",
            "| \u001b[39m4        \u001b[39m | \u001b[39m0.1404   \u001b[39m | \u001b[39m0.701    \u001b[39m | \u001b[39m0.2387   \u001b[39m | \u001b[39m0.01214  \u001b[39m | \u001b[39m10.59    \u001b[39m | \u001b[39m12.47    \u001b[39m | \u001b[39m194.6    \u001b[39m | \u001b[39m0.3819   \u001b[39m | \u001b[39m0.1328   \u001b[39m | \u001b[39m0.9562   \u001b[39m |\n",
            "| \u001b[39m5        \u001b[39m | \u001b[39m0.1428   \u001b[39m | \u001b[39m0.9924   \u001b[39m | \u001b[39m0.01798  \u001b[39m | \u001b[39m0.1347   \u001b[39m | \u001b[39m10.35    \u001b[39m | \u001b[39m15.11    \u001b[39m | \u001b[39m667.2    \u001b[39m | \u001b[39m0.5818   \u001b[39m | \u001b[39m0.1184   \u001b[39m | \u001b[39m0.684    \u001b[39m |\n",
            "| \u001b[39m6        \u001b[39m | \u001b[39m0.1502   \u001b[39m | \u001b[39m0.8179   \u001b[39m | \u001b[39m0.2307   \u001b[39m | \u001b[39m0.0451   \u001b[39m | \u001b[39m7.145    \u001b[39m | \u001b[39m17.2     \u001b[39m | \u001b[39m977.5    \u001b[39m | \u001b[39m0.8849   \u001b[39m | \u001b[39m0.4236   \u001b[39m | \u001b[39m0.8395   \u001b[39m |\n",
            "| \u001b[39m7        \u001b[39m | \u001b[39m0.145    \u001b[39m | \u001b[39m0.7419   \u001b[39m | \u001b[39m0.1021   \u001b[39m | \u001b[39m0.03493  \u001b[39m | \u001b[39m6.615    \u001b[39m | \u001b[39m1.852    \u001b[39m | \u001b[39m554.9    \u001b[39m | \u001b[39m0.3763   \u001b[39m | \u001b[39m0.6335   \u001b[39m | \u001b[39m0.852    \u001b[39m |\n",
            "| \u001b[39m8        \u001b[39m | \u001b[39m0.1499   \u001b[39m | \u001b[39m0.657    \u001b[39m | \u001b[39m0.2802   \u001b[39m | \u001b[39m0.1425   \u001b[39m | \u001b[39m10.63    \u001b[39m | \u001b[39m8.368    \u001b[39m | \u001b[39m426.9    \u001b[39m | \u001b[39m0.2043   \u001b[39m | \u001b[39m0.3491   \u001b[39m | \u001b[39m0.6986   \u001b[39m |\n",
            "| \u001b[39m9        \u001b[39m | \u001b[39m0.1457   \u001b[39m | \u001b[39m0.6694   \u001b[39m | \u001b[39m0.29     \u001b[39m | \u001b[39m0.144    \u001b[39m | \u001b[39m10.58    \u001b[39m | \u001b[39m14.89    \u001b[39m | \u001b[39m406.3    \u001b[39m | \u001b[39m0.09206  \u001b[39m | \u001b[39m0.5171   \u001b[39m | \u001b[39m0.8035   \u001b[39m |\n",
            "| \u001b[39m10       \u001b[39m | \u001b[39m0.1468   \u001b[39m | \u001b[39m0.6354   \u001b[39m | \u001b[39m0.1584   \u001b[39m | \u001b[39m0.1489   \u001b[39m | \u001b[39m8.345    \u001b[39m | \u001b[39m7.376    \u001b[39m | \u001b[39m824.9    \u001b[39m | \u001b[39m0.7543   \u001b[39m | \u001b[39m0.3818   \u001b[39m | \u001b[39m0.8536   \u001b[39m |\n",
            "| \u001b[39m11       \u001b[39m | \u001b[39m0.1446   \u001b[39m | \u001b[39m0.8858   \u001b[39m | \u001b[39m0.007759 \u001b[39m | \u001b[39m0.1469   \u001b[39m | \u001b[39m6.534    \u001b[39m | \u001b[39m5.482    \u001b[39m | \u001b[39m291.9    \u001b[39m | \u001b[39m0.8868   \u001b[39m | \u001b[39m0.4151   \u001b[39m | \u001b[39m0.6474   \u001b[39m |\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from bayes_opt import BayesianOptimization\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split, StratifiedKFold\n",
        "def evaluate_model(n_estimators, learning_rate, max_depth, gamma, reg_alpha, reg_lambda, subsample, colsample_bytree, min_child_weight):\n",
        "    params = {\n",
        "        'n_estimators': int(n_estimators),\n",
        "        'learning_rate': learning_rate,\n",
        "        'max_depth': int(max_depth),\n",
        "        'gamma': gamma,\n",
        "        'reg_alpha': reg_alpha,\n",
        "        'reg_lambda': reg_lambda,\n",
        "        'subsample': subsample,\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'eval_metric': 'logloss',\n",
        "        'random_state': 100\n",
        "    }\n",
        "\n",
        "    # Use StratifiedKFold to maintain class balance\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    fold_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
        "        # Split the data\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        # Preprocess the data\n",
        "        X_train_fold_preprocessed = preprocessor.fit_transform(X_train_fold)\n",
        "        X_val_fold_preprocessed = preprocessor.transform(X_val_fold)\n",
        "\n",
        "        # Apply SMOTE\n",
        "        X_resampled, y_resampled = SMOTE(random_state=100).fit_resample(X_train_fold_preprocessed, y_train_fold)\n",
        "\n",
        "        # Train the XGBoost model\n",
        "        model = XGBClassifier(**params)\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_proba = model.predict_proba(X_val_fold_preprocessed)[:, 1]\n",
        "\n",
        "        # Custom scoring function\n",
        "        solution = pd.DataFrame(y_val_fold, columns=[\"target\"])\n",
        "        submission = pd.DataFrame(y_pred_proba, columns=[\"pred\"])\n",
        "        fold_score = score(solution, submission, row_id_column_name=\"target\", min_tpr=0.80)\n",
        "        fold_scores.append(fold_score)\n",
        "\n",
        "    # Return the average score across folds\n",
        "    return np.mean(fold_scores)\n",
        "\n",
        "# Set bounds for hyperparameters\n",
        "param_bounds = {\n",
        "    'n_estimators': (100, 1000),  # Number of trees\n",
        "    'learning_rate': (0.01, 0.15),  # Learning rate\n",
        "    'max_depth': (4, 15),  # Depth of trees\n",
        "    'gamma': (0, 0.3),  # Minimum loss reduction\n",
        "    'reg_alpha': (0, 1),  # L1 regularization\n",
        "    'reg_lambda': (0.1, 1),  # L2 regularization\n",
        "    'subsample': (0.6, 1.0),  # Subsample ratio\n",
        "    'colsample_bytree': (0.6, 1.0),  # Subsample ratio of columns\n",
        "    'min_child_weight': (1, 20)  # Minimum sum of instance weight\n",
        "}\n",
        "\n",
        "# Initialize Bayesian Optimization\n",
        "optimizer = BayesianOptimization(\n",
        "    f=evaluate_model,  # Objective function\n",
        "    pbounds=param_bounds,\n",
        "    random_state=100,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Perform optimization\n",
        "optimizer.maximize(\n",
        "    init_points=10,  # Random points to explore first\n",
        "    n_iter=30  # Number of optimization iterations\n",
        ")\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", optimizer.max['params'])\n",
        "print(\"Best Score:\", optimizer.max['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akjwoYZEKAvz"
      },
      "outputs": [],
      "source": [
        "best_xgb_params = {\n",
        "    'colsample_bytree': 0.8659,\n",
        "    'gamma': 0.1787,\n",
        "    'learning_rate': 0.0214,\n",
        "    'max_depth': int(4.9),  # Convert to int as required by XGBoost\n",
        "    'min_child_weight': 17.38,\n",
        "    'n_estimators': int(130.67),  # Convert to int as required by XGBoost\n",
        "    'reg_alpha': 0.8864,\n",
        "    'reg_lambda': 0.3854,\n",
        "    'subsample': 0.9212,\n",
        "    'random_state': 42\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VUcMXfmaMhuO",
        "outputId": "44c5d04c-9e36-4876-ba6b-e1b112fd25f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
            "Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.16\n"
          ]
        }
      ],
      "source": [
        "pip install \"dask[dataframe]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REVROUcazXND",
        "outputId": "a6ba262e-edc4-4c23-b61a-07a9d117abf3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py:344: UserWarning: You're attempting to register an np.ndarray. Currently, the optimizer internally sorts parameters by key and expects any registered array to respect this order. In future versions this behaviour will change and the order as given by the pbounds dictionary will be used. If you wish to retain sorted parameters, please manually sort your pbounds dictionary before constructing the optimizer.\n",
            "  warn(msg, stacklevel=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[39m1        \u001b[39m | \u001b[39m0.1508   \u001b[39m | \u001b[39m0.8174   \u001b[39m | \u001b[39m0.09073  \u001b[39m | \u001b[39m8.094    \u001b[39m | \u001b[39m17.05    \u001b[39m | \u001b[39m104.2    \u001b[39m | \u001b[39m14.86    \u001b[39m | \u001b[39m0.6707   \u001b[39m | \u001b[39m0.8433   \u001b[39m | \u001b[39m0.6547   \u001b[39m |\n",
            "| \u001b[39m2        \u001b[39m | \u001b[39m0.1447   \u001b[39m | \u001b[39m0.83     \u001b[39m | \u001b[39m0.2685   \u001b[39m | \u001b[39m5.51     \u001b[39m | \u001b[39m4.521    \u001b[39m | \u001b[39m197.5    \u001b[39m | \u001b[39m18.79    \u001b[39m | \u001b[39m0.9786   \u001b[39m | \u001b[39m0.8305   \u001b[39m | \u001b[39m0.6688   \u001b[39m |\n",
            "| \u001b[35m3        \u001b[39m | \u001b[35m0.1541   \u001b[39m | \u001b[35m0.9265   \u001b[39m | \u001b[35m0.08948  \u001b[39m | \u001b[35m8.18     \u001b[39m | \u001b[35m18.86    \u001b[39m | \u001b[35m835.9    \u001b[39m | \u001b[35m23.44    \u001b[39m | \u001b[35m0.1754   \u001b[39m | \u001b[35m0.4355   \u001b[39m | \u001b[35m0.6023   \u001b[39m |\n",
            "| \u001b[39m4        \u001b[39m | \u001b[39m0.1538   \u001b[39m | \u001b[39m0.701    \u001b[39m | \u001b[39m0.2407   \u001b[39m | \u001b[39m3.183    \u001b[39m | \u001b[39m12.38    \u001b[39m | \u001b[39m643.4    \u001b[39m | \u001b[39m14.21    \u001b[39m | \u001b[39m0.3819   \u001b[39m | \u001b[39m0.1328   \u001b[39m | \u001b[39m0.9562   \u001b[39m |\n",
            "| \u001b[39m5        \u001b[39m | \u001b[39m0.154    \u001b[39m | \u001b[39m0.9924   \u001b[39m | \u001b[39m0.02738  \u001b[39m | \u001b[39m13.69    \u001b[39m | \u001b[39m11.96    \u001b[39m | \u001b[39m768.2    \u001b[39m | \u001b[39m35.21    \u001b[39m | \u001b[39m0.5818   \u001b[39m | \u001b[39m0.1184   \u001b[39m | \u001b[39m0.684    \u001b[39m |\n",
            "| \u001b[39m6        \u001b[39m | \u001b[39m0.1456   \u001b[39m | \u001b[39m0.8179   \u001b[39m | \u001b[39m0.233    \u001b[39m | \u001b[39m6.008    \u001b[39m | \u001b[39m6.432    \u001b[39m | \u001b[39m867.2    \u001b[39m | \u001b[39m49.0     \u001b[39m | \u001b[39m0.8849   \u001b[39m | \u001b[39m0.4236   \u001b[39m | \u001b[39m0.8395   \u001b[39m |\n",
            "| \u001b[39m7        \u001b[39m | \u001b[39m0.1466   \u001b[39m | \u001b[39m0.7419   \u001b[39m | \u001b[39m0.1087   \u001b[39m | \u001b[39m5.137    \u001b[39m | \u001b[39m5.516    \u001b[39m | \u001b[39m140.4    \u001b[39m | \u001b[39m30.22    \u001b[39m | \u001b[39m0.3763   \u001b[39m | \u001b[39m0.6335   \u001b[39m | \u001b[39m0.852    \u001b[39m |\n",
            "| \u001b[39m8        \u001b[39m | \u001b[39m0.142    \u001b[39m | \u001b[39m0.657    \u001b[39m | \u001b[39m0.2808   \u001b[39m | \u001b[39m14.36    \u001b[39m | \u001b[39m12.44    \u001b[39m | \u001b[39m449.0    \u001b[39m | \u001b[39m24.53    \u001b[39m | \u001b[39m0.2043   \u001b[39m | \u001b[39m0.3491   \u001b[39m | \u001b[39m0.6986   \u001b[39m |\n",
            "| \u001b[39m9        \u001b[39m | \u001b[39m0.1461   \u001b[39m | \u001b[39m0.6694   \u001b[39m | \u001b[39m0.2903   \u001b[39m | \u001b[39m14.48    \u001b[39m | \u001b[39m12.36    \u001b[39m | \u001b[39m758.2    \u001b[39m | \u001b[39m23.62    \u001b[39m | \u001b[39m0.09206  \u001b[39m | \u001b[39m0.5171   \u001b[39m | \u001b[39m0.8035   \u001b[39m |\n",
            "| \u001b[39m10       \u001b[39m | \u001b[39m0.1448   \u001b[39m | \u001b[39m0.6354   \u001b[39m | \u001b[39m0.1631   \u001b[39m | \u001b[39m14.91    \u001b[39m | \u001b[39m8.506    \u001b[39m | \u001b[39m402.0    \u001b[39m | \u001b[39m42.22    \u001b[39m | \u001b[39m0.7543   \u001b[39m | \u001b[39m0.3818   \u001b[39m | \u001b[39m0.8536   \u001b[39m |\n",
            "| \u001b[35m11       \u001b[39m | \u001b[35m0.1555   \u001b[39m | \u001b[35m0.8858   \u001b[39m | \u001b[35m0.0175   \u001b[39m | \u001b[35m14.73    \u001b[39m | \u001b[35m5.377    \u001b[39m | \u001b[35m312.3    \u001b[39m | \u001b[35m18.53    \u001b[39m | \u001b[35m0.8868   \u001b[39m | \u001b[35m0.4151   \u001b[39m | \u001b[35m0.6474   \u001b[39m |\n",
            "| \u001b[39m12       \u001b[39m | \u001b[39m0.152    \u001b[39m | \u001b[39m0.9232   \u001b[39m | \u001b[39m0.1877   \u001b[39m | \u001b[39m14.34    \u001b[39m | \u001b[39m5.968    \u001b[39m | \u001b[39m311.0    \u001b[39m | \u001b[39m19.19    \u001b[39m | \u001b[39m0.7657   \u001b[39m | \u001b[39m0.6212   \u001b[39m | \u001b[39m0.832    \u001b[39m |\n",
            "| \u001b[39m13       \u001b[39m | \u001b[39m0.1462   \u001b[39m | \u001b[39m0.9017   \u001b[39m | \u001b[39m0.217    \u001b[39m | \u001b[39m10.56    \u001b[39m | \u001b[39m17.22    \u001b[39m | \u001b[39m835.0    \u001b[39m | \u001b[39m23.22    \u001b[39m | \u001b[39m0.3625   \u001b[39m | \u001b[39m0.338    \u001b[39m | \u001b[39m0.8654   \u001b[39m |\n",
            "| \u001b[39m14       \u001b[39m | \u001b[39m0.1483   \u001b[39m | \u001b[39m0.7136   \u001b[39m | \u001b[39m0.2696   \u001b[39m | \u001b[39m14.16    \u001b[39m | \u001b[39m4.783    \u001b[39m | \u001b[39m312.6    \u001b[39m | \u001b[39m21.28    \u001b[39m | \u001b[39m0.5534   \u001b[39m | \u001b[39m0.966    \u001b[39m | \u001b[39m0.9157   \u001b[39m |\n",
            "| \u001b[39m15       \u001b[39m | \u001b[39m0.1504   \u001b[39m | \u001b[39m0.6648   \u001b[39m | \u001b[39m0.02527  \u001b[39m | \u001b[39m8.885    \u001b[39m | \u001b[39m19.44    \u001b[39m | \u001b[39m837.4    \u001b[39m | \u001b[39m24.15    \u001b[39m | \u001b[39m0.08851  \u001b[39m | \u001b[39m0.3437   \u001b[39m | \u001b[39m0.602    \u001b[39m |\n",
            "| \u001b[39m16       \u001b[39m | \u001b[39m0.1483   \u001b[39m | \u001b[39m0.8652   \u001b[39m | \u001b[39m0.2204   \u001b[39m | \u001b[39m5.717    \u001b[39m | \u001b[39m11.85    \u001b[39m | \u001b[39m643.9    \u001b[39m | \u001b[39m16.17    \u001b[39m | \u001b[39m0.1806   \u001b[39m | \u001b[39m0.472    \u001b[39m | \u001b[39m0.8447   \u001b[39m |\n",
            "| \u001b[39m17       \u001b[39m | \u001b[39m0.1511   \u001b[39m | \u001b[39m0.9095   \u001b[39m | \u001b[39m0.05166  \u001b[39m | \u001b[39m13.96    \u001b[39m | \u001b[39m13.51    \u001b[39m | \u001b[39m767.3    \u001b[39m | \u001b[39m33.65    \u001b[39m | \u001b[39m0.1997   \u001b[39m | \u001b[39m0.5536   \u001b[39m | \u001b[39m0.8651   \u001b[39m |\n",
            "| \u001b[39m18       \u001b[39m | \u001b[39m0.1468   \u001b[39m | \u001b[39m0.6051   \u001b[39m | \u001b[39m0.1984   \u001b[39m | \u001b[39m6.114    \u001b[39m | \u001b[39m15.88    \u001b[39m | \u001b[39m836.6    \u001b[39m | \u001b[39m23.91    \u001b[39m | \u001b[39m0.9091   \u001b[39m | \u001b[39m0.4641   \u001b[39m | \u001b[39m0.7953   \u001b[39m |\n",
            "| \u001b[39m19       \u001b[39m | \u001b[39m0.1498   \u001b[39m | \u001b[39m0.8558   \u001b[39m | \u001b[39m0.1443   \u001b[39m | \u001b[39m12.74    \u001b[39m | \u001b[39m10.47    \u001b[39m | \u001b[39m766.7    \u001b[39m | \u001b[39m34.05    \u001b[39m | \u001b[39m0.1188   \u001b[39m | \u001b[39m0.7455   \u001b[39m | \u001b[39m0.737    \u001b[39m |\n",
            "| \u001b[39m20       \u001b[39m | \u001b[39m0.1488   \u001b[39m | \u001b[39m0.6339   \u001b[39m | \u001b[39m0.2894   \u001b[39m | \u001b[39m13.82    \u001b[39m | \u001b[39m7.091    \u001b[39m | \u001b[39m311.0    \u001b[39m | \u001b[39m17.74    \u001b[39m | \u001b[39m0.931    \u001b[39m | \u001b[39m0.8518   \u001b[39m | \u001b[39m0.8027   \u001b[39m |\n",
            "| \u001b[39m21       \u001b[39m | \u001b[39m0.1491   \u001b[39m | \u001b[39m0.8543   \u001b[39m | \u001b[39m0.1292   \u001b[39m | \u001b[39m14.39    \u001b[39m | \u001b[39m5.652    \u001b[39m | \u001b[39m314.1    \u001b[39m | \u001b[39m16.16    \u001b[39m | \u001b[39m0.09425  \u001b[39m | \u001b[39m0.9465   \u001b[39m | \u001b[39m0.7962   \u001b[39m |\n",
            "| \u001b[39m22       \u001b[39m | \u001b[39m0.1502   \u001b[39m | \u001b[39m0.998    \u001b[39m | \u001b[39m0.0982   \u001b[39m | \u001b[39m11.54    \u001b[39m | \u001b[39m14.18    \u001b[39m | \u001b[39m768.2    \u001b[39m | \u001b[39m37.47    \u001b[39m | \u001b[39m0.03076  \u001b[39m | \u001b[39m0.143    \u001b[39m | \u001b[39m0.894    \u001b[39m |\n",
            "| \u001b[39m23       \u001b[39m | \u001b[39m0.1488   \u001b[39m | \u001b[39m0.6607   \u001b[39m | \u001b[39m0.08862  \u001b[39m | \u001b[39m14.05    \u001b[39m | \u001b[39m10.97    \u001b[39m | \u001b[39m770.9    \u001b[39m | \u001b[39m34.17    \u001b[39m | \u001b[39m0.2876   \u001b[39m | \u001b[39m0.2698   \u001b[39m | \u001b[39m0.7897   \u001b[39m |\n",
            "| \u001b[39m24       \u001b[39m | \u001b[39m0.145    \u001b[39m | \u001b[39m0.837    \u001b[39m | \u001b[39m0.2967   \u001b[39m | \u001b[39m7.531    \u001b[39m | \u001b[39m19.33    \u001b[39m | \u001b[39m836.6    \u001b[39m | \u001b[39m25.43    \u001b[39m | \u001b[39m0.298    \u001b[39m | \u001b[39m0.5902   \u001b[39m | \u001b[39m0.9698   \u001b[39m |\n",
            "| \u001b[39m25       \u001b[39m | \u001b[39m0.1471   \u001b[39m | \u001b[39m0.6482   \u001b[39m | \u001b[39m0.1489   \u001b[39m | \u001b[39m7.95     \u001b[39m | \u001b[39m17.58    \u001b[39m | \u001b[39m836.7    \u001b[39m | \u001b[39m22.97    \u001b[39m | \u001b[39m0.5422   \u001b[39m | \u001b[39m0.616    \u001b[39m | \u001b[39m0.8983   \u001b[39m |\n",
            "| \u001b[39m26       \u001b[39m | \u001b[39m0.149    \u001b[39m | \u001b[39m0.6518   \u001b[39m | \u001b[39m0.1084   \u001b[39m | \u001b[39m13.68    \u001b[39m | \u001b[39m15.23    \u001b[39m | \u001b[39m769.6    \u001b[39m | \u001b[39m32.23    \u001b[39m | \u001b[39m0.2987   \u001b[39m | \u001b[39m0.6478   \u001b[39m | \u001b[39m0.981    \u001b[39m |\n",
            "| \u001b[39m27       \u001b[39m | \u001b[39m0.1456   \u001b[39m | \u001b[39m0.9111   \u001b[39m | \u001b[39m0.2281   \u001b[39m | \u001b[39m12.59    \u001b[39m | \u001b[39m13.08    \u001b[39m | \u001b[39m769.6    \u001b[39m | \u001b[39m34.65    \u001b[39m | \u001b[39m0.04128  \u001b[39m | \u001b[39m0.1888   \u001b[39m | \u001b[39m0.8373   \u001b[39m |\n",
            "| \u001b[39m28       \u001b[39m | \u001b[39m0.1448   \u001b[39m | \u001b[39m0.6051   \u001b[39m | \u001b[39m0.2851   \u001b[39m | \u001b[39m14.86    \u001b[39m | \u001b[39m9.589    \u001b[39m | \u001b[39m765.6    \u001b[39m | \u001b[39m33.1     \u001b[39m | \u001b[39m0.7124   \u001b[39m | \u001b[39m0.3113   \u001b[39m | \u001b[39m0.9846   \u001b[39m |\n",
            "| \u001b[39m29       \u001b[39m | \u001b[39m0.1458   \u001b[39m | \u001b[39m0.7872   \u001b[39m | \u001b[39m0.14     \u001b[39m | \u001b[39m13.81    \u001b[39m | \u001b[39m11.64    \u001b[39m | \u001b[39m768.0    \u001b[39m | \u001b[39m35.96    \u001b[39m | \u001b[39m0.08237  \u001b[39m | \u001b[39m0.2133   \u001b[39m | \u001b[39m0.6677   \u001b[39m |\n",
            "| \u001b[39m30       \u001b[39m | \u001b[39m0.1483   \u001b[39m | \u001b[39m0.8713   \u001b[39m | \u001b[39m0.2757   \u001b[39m | \u001b[39m6.665    \u001b[39m | \u001b[39m12.62    \u001b[39m | \u001b[39m515.7    \u001b[39m | \u001b[39m13.94    \u001b[39m | \u001b[39m0.199    \u001b[39m | \u001b[39m0.2374   \u001b[39m | \u001b[39m0.9969   \u001b[39m |\n",
            "| \u001b[39m31       \u001b[39m | \u001b[39m0.1482   \u001b[39m | \u001b[39m0.856    \u001b[39m | \u001b[39m0.2093   \u001b[39m | \u001b[39m4.166    \u001b[39m | \u001b[39m17.5     \u001b[39m | \u001b[39m336.1    \u001b[39m | \u001b[39m49.28    \u001b[39m | \u001b[39m0.526    \u001b[39m | \u001b[39m0.9183   \u001b[39m | \u001b[39m0.6392   \u001b[39m |\n",
            "| \u001b[39m32       \u001b[39m | \u001b[39m0.1487   \u001b[39m | \u001b[39m0.6132   \u001b[39m | \u001b[39m0.0711   \u001b[39m | \u001b[39m5.427    \u001b[39m | \u001b[39m1.141    \u001b[39m | \u001b[39m107.7    \u001b[39m | \u001b[39m36.26    \u001b[39m | \u001b[39m0.003042 \u001b[39m | \u001b[39m0.4491   \u001b[39m | \u001b[39m0.8603   \u001b[39m |\n",
            "| \u001b[39m33       \u001b[39m | \u001b[39m0.1441   \u001b[39m | \u001b[39m0.8696   \u001b[39m | \u001b[39m0.2607   \u001b[39m | \u001b[39m7.485    \u001b[39m | \u001b[39m12.63    \u001b[39m | \u001b[39m521.1    \u001b[39m | \u001b[39m33.12    \u001b[39m | \u001b[39m0.1812   \u001b[39m | \u001b[39m0.6345   \u001b[39m | \u001b[39m0.752    \u001b[39m |\n",
            "| \u001b[39m34       \u001b[39m | \u001b[39m0.1482   \u001b[39m | \u001b[39m0.894    \u001b[39m | \u001b[39m0.09855  \u001b[39m | \u001b[39m8.68     \u001b[39m | \u001b[39m4.775    \u001b[39m | \u001b[39m196.2    \u001b[39m | \u001b[39m22.99    \u001b[39m | \u001b[39m0.9581   \u001b[39m | \u001b[39m0.3898   \u001b[39m | \u001b[39m0.8876   \u001b[39m |\n",
            "| \u001b[39m35       \u001b[39m | \u001b[39m0.1473   \u001b[39m | \u001b[39m0.8678   \u001b[39m | \u001b[39m0.1636   \u001b[39m | \u001b[39m5.657    \u001b[39m | \u001b[39m13.29    \u001b[39m | \u001b[39m842.7    \u001b[39m | \u001b[39m36.99    \u001b[39m | \u001b[39m0.5594   \u001b[39m | \u001b[39m0.4389   \u001b[39m | \u001b[39m0.6207   \u001b[39m |\n",
            "| \u001b[39m36       \u001b[39m | \u001b[39m0.1458   \u001b[39m | \u001b[39m0.9422   \u001b[39m | \u001b[39m0.2046   \u001b[39m | \u001b[39m3.922    \u001b[39m | \u001b[39m16.67    \u001b[39m | \u001b[39m386.5    \u001b[39m | \u001b[39m12.22    \u001b[39m | \u001b[39m0.475    \u001b[39m | \u001b[39m0.2598   \u001b[39m | \u001b[39m0.9465   \u001b[39m |\n",
            "| \u001b[39m37       \u001b[39m | \u001b[39m0.1449   \u001b[39m | \u001b[39m0.9784   \u001b[39m | \u001b[39m0.2292   \u001b[39m | \u001b[39m3.366    \u001b[39m | \u001b[39m4.083    \u001b[39m | \u001b[39m751.2    \u001b[39m | \u001b[39m27.47    \u001b[39m | \u001b[39m0.6621   \u001b[39m | \u001b[39m0.7758   \u001b[39m | \u001b[39m0.8513   \u001b[39m |\n",
            "| \u001b[39m38       \u001b[39m | \u001b[39m0.144    \u001b[39m | \u001b[39m0.9288   \u001b[39m | \u001b[39m0.2939   \u001b[39m | \u001b[39m6.788    \u001b[39m | \u001b[39m4.249    \u001b[39m | \u001b[39m353.1    \u001b[39m | \u001b[39m34.65    \u001b[39m | \u001b[39m0.9197   \u001b[39m | \u001b[39m0.8159   \u001b[39m | \u001b[39m0.6288   \u001b[39m |\n",
            "| \u001b[39m39       \u001b[39m | \u001b[39m0.1426   \u001b[39m | \u001b[39m0.8391   \u001b[39m | \u001b[39m0.2418   \u001b[39m | \u001b[39m8.94     \u001b[39m | \u001b[39m11.86    \u001b[39m | \u001b[39m901.1    \u001b[39m | \u001b[39m35.87    \u001b[39m | \u001b[39m0.678    \u001b[39m | \u001b[39m0.2174   \u001b[39m | \u001b[39m0.6355   \u001b[39m |\n",
            "| \u001b[39m40       \u001b[39m | \u001b[39m0.1439   \u001b[39m | \u001b[39m0.9714   \u001b[39m | \u001b[39m0.2798   \u001b[39m | \u001b[39m12.18    \u001b[39m | \u001b[39m5.739    \u001b[39m | \u001b[39m366.9    \u001b[39m | \u001b[39m43.0     \u001b[39m | \u001b[39m0.8674   \u001b[39m | \u001b[39m0.9439   \u001b[39m | \u001b[39m0.7178   \u001b[39m |\n",
            "=====================================================================================================================================\n",
            "Best Parameters for LightGBM: {'colsample_bytree': 0.8857803204240369, 'learning_rate': 0.017500222835261432, 'max_depth': 14.73208362393005, 'min_child_weight': 5.377286276523429, 'n_estimators': 312.2851040432462, 'num_leaves': 18.527708662860555, 'reg_alpha': 0.8868270176102878, 'reg_lambda': 0.41507705814376017, 'subsample': 0.6473977317707736}\n",
            "Best Score for LightGBM: 0.15548873070746283\n"
          ]
        }
      ],
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split, StratifiedKFold\n",
        "def evaluate_lgbm(num_leaves, learning_rate, max_depth, reg_alpha, reg_lambda, subsample, colsample_bytree, min_child_weight, n_estimators):\n",
        "    params = {\n",
        "        'n_estimators': int(n_estimators),\n",
        "        'learning_rate': learning_rate,\n",
        "        'max_depth': int(max_depth),\n",
        "        'num_leaves': int(num_leaves),\n",
        "        'reg_alpha': reg_alpha,\n",
        "        'reg_lambda': reg_lambda,\n",
        "        'subsample': subsample,\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'random_state': 100,\n",
        "        'verbose': -1\n",
        "    }\n",
        "    return cross_validate_model(LGBMClassifier, params)\n",
        "\n",
        "def cross_validate_model(ModelClass, params):\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    fold_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
        "        # Split the data\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        # Preprocess the data\n",
        "        X_train_fold_preprocessed = preprocessor.fit_transform(X_train_fold)\n",
        "        X_val_fold_preprocessed = preprocessor.transform(X_val_fold)\n",
        "\n",
        "        # Apply SMOTE\n",
        "        X_resampled, y_resampled = SMOTE(random_state=100).fit_resample(X_train_fold_preprocessed, y_train_fold)\n",
        "\n",
        "        # Train the model\n",
        "        model = ModelClass(**params)\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_proba = model.predict_proba(X_val_fold_preprocessed)[:, 1]\n",
        "\n",
        "        # Custom scoring function\n",
        "        solution = pd.DataFrame(y_val_fold, columns=[\"target\"])\n",
        "        submission = pd.DataFrame(y_pred_proba, columns=[\"pred\"])\n",
        "        fold_score = score(solution, submission, row_id_column_name=\"target\", min_tpr=0.80)\n",
        "        fold_scores.append(fold_score)\n",
        "\n",
        "    # Return the average score across folds\n",
        "    return np.mean(fold_scores)\n",
        "\n",
        "lgbm_param_bounds = {\n",
        "    'num_leaves': (10, 50),\n",
        "    'learning_rate': (0.01, 0.3),\n",
        "    'max_depth': (3, 15),\n",
        "    'reg_alpha': (0, 1),\n",
        "    'reg_lambda': (0.1, 1),\n",
        "    'subsample': (0.6, 1.0),\n",
        "    'colsample_bytree': (0.6, 1.0),\n",
        "    'min_child_weight': (1, 20),\n",
        "    'n_estimators': (100, 1000)\n",
        "}\n",
        "\n",
        "lgbm_optimizer = BayesianOptimization(\n",
        "    f=evaluate_lgbm,\n",
        "    pbounds=lgbm_param_bounds,\n",
        "    random_state=100,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "lgbm_optimizer.maximize(init_points=10, n_iter=30)\n",
        "print(\"Best Parameters for LightGBM:\", lgbm_optimizer.max['params'])\n",
        "print(\"Best Score for LightGBM:\", lgbm_optimizer.max['target'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}